{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport json\nimport random as random_\nimport re\nfrom glob import iglob\n\nfrom typing import List, Dict, Tuple, Set, Any,  Union, Optional, Callable\nfrom typing_extensions import TypedDict, Literal\nfrom math import floor","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.552094Z","iopub.execute_input":"2022-03-30T10:44:15.552409Z","iopub.status.idle":"2022-03-30T10:44:15.557543Z","shell.execute_reply.started":"2022-03-30T10:44:15.552376Z","shell.execute_reply":"2022-03-30T10:44:15.556636Z"},"trusted":true},"execution_count":303,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.628486Z","iopub.execute_input":"2022-03-30T10:44:15.629044Z","iopub.status.idle":"2022-03-30T10:44:15.634144Z","shell.execute_reply.started":"2022-03-30T10:44:15.629011Z","shell.execute_reply":"2022-03-30T10:44:15.633148Z"},"trusted":true},"execution_count":304,"outputs":[{"name":"stdout","text":"2.6.2\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"DATASET_BASE = \"../input/ludwig-music-dataset-moods-and-subgenres\"\nMFCCS  = f\"{DATASET_BASE}/mfccs\"\nLABELS = f\"{DATASET_BASE}/labels.json\"\nSUBGENERES = f\"{DATASET_BASE}/subgeneres.json\"\nCHECKPOINT = \"./checkpoint/saved_model.h5\"\nBATCH_SIZE = 25\n\nSEED = random_.randint(0, 100)\nrandom = random_.Random(SEED)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.698387Z","iopub.execute_input":"2022-03-30T10:44:15.698629Z","iopub.status.idle":"2022-03-30T10:44:15.703837Z","shell.execute_reply.started":"2022-03-30T10:44:15.698600Z","shell.execute_reply":"2022-03-30T10:44:15.702949Z"},"trusted":true},"execution_count":305,"outputs":[]},{"cell_type":"markdown","source":"## JSON Declaration and other Dicts ","metadata":{}},{"cell_type":"code","source":"\n\nclass N(TypedDict): # A number \n    N: Union[float, int]\n\nclass S(TypedDict): # A string\n    S: str\n\nclass L(TypedDict): # A list of strings\n    L: List[S]\n\nclass Track(TypedDict):\n    # IDs\n    PK: S\n    mbid: S\n\n    # Genres: \n    genre: S\n    subgenres: L\n    otherSubgenres: Optional[L]\n\n    # Moods\n    aggressive: Optional[N]\n    happy: Optional[N]\n    party: Optional[N]\n    acoustic: Optional[N] \n    electronic: Optional[N]\n    sad: Optional[N]\n    relaxed: Optional[N]\n\n    # Metadata\n    preview: S\n    name: Optional[S]\n    artist: Optional[S]\n    popularity: Optional[N]\n    album: Optional[S]\n    \n\nclass LabelsJson(TypedDict):\n    tracks: Dict[str, Track]\n\nclass Mfcc(TypedDict):\n    mfccs: np.ndarray\n    track_id: str\n    splits: int\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.762564Z","iopub.execute_input":"2022-03-30T10:44:15.763238Z","iopub.status.idle":"2022-03-30T10:44:15.774699Z","shell.execute_reply.started":"2022-03-30T10:44:15.763201Z","shell.execute_reply":"2022-03-30T10:44:15.773872Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"code","source":"def load_json(path:str) -> Dict[str, Any]:\n    \"\"\"Loads a json file \n\n    Args:\n        path (str): json file path\n\n    Returns:\n        Dict: A dictionary indexed by a string\n    \"\"\"\n    with open(path, \"r\") as f:\n        return json.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.826210Z","iopub.execute_input":"2022-03-30T10:44:15.826849Z","iopub.status.idle":"2022-03-30T10:44:15.831640Z","shell.execute_reply.started":"2022-03-30T10:44:15.826810Z","shell.execute_reply":"2022-03-30T10:44:15.830671Z"},"trusted":true},"execution_count":307,"outputs":[]},{"cell_type":"code","source":"def get_subgenres(parent_genre: str, subgenres: List[str]):\n    \"\"\"Get all subgenres of a given genre\n\n    Args:\n        parent_genre (str): \n        subgenres (List[str]): List of subgenres to match with a parent genre\n\n    Returns:\n        List[str]: List of subgenres\n    \"\"\"\n    return list(filter(lambda s: parent_genre in s.split(\"---\")[0] ,subgenres))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.889343Z","iopub.execute_input":"2022-03-30T10:44:15.889920Z","iopub.status.idle":"2022-03-30T10:44:15.895096Z","shell.execute_reply.started":"2022-03-30T10:44:15.889799Z","shell.execute_reply":"2022-03-30T10:44:15.894147Z"},"trusted":true},"execution_count":308,"outputs":[]},{"cell_type":"code","source":"def load_mfccs(subgenres_list: List[str], subgenres: Dict[str, List[str]], search_path: str = MFCCS):\n    \n    track_set: Set[str] = set() # List of track ids among all subgenres_list subgenres\n\n    track_splits: List[Mfcc] = [] \n\n    for g in subgenres_list:\n        track_set.update(subgenres[g])\n\n    for npy in iglob(search_path + '/**/*.npy', recursive=True):\n        match = re.search(r\"[a-zA-Z0-9]+.npy\", npy)\n\n        if (match and match.group(0)):\n            track_id = match.group(0).replace(\".npy\", \"\")\n            if track_id in track_set: \n                try:\n                    mfccs_splits = np.load(npy)\n                    track_splits.append({\"mfccs\": mfccs_splits, \"track_id\": track_id, \"splits\": len(mfccs_splits)})\n                except IOError:\n                    print(f\"File {npy} not found\")\n\n    return track_splits\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:15.944060Z","iopub.execute_input":"2022-03-30T10:44:15.944524Z","iopub.status.idle":"2022-03-30T10:44:15.952096Z","shell.execute_reply.started":"2022-03-30T10:44:15.944492Z","shell.execute_reply":"2022-03-30T10:44:15.951361Z"},"trusted":true},"execution_count":309,"outputs":[]},{"cell_type":"code","source":"def train_test_val(ds: List[Mfcc], test=0.01, val=0.2):\n    # TRAIN     \n    train_slice = floor(len(ds) * (1 - val - test))\n    train = ds[:train_slice]\n\n    rest = ds[train_slice:]\n    rest_slice =  floor(len(rest) * (1 - (test / ( test + val))))\n\n    # TEST\n    val = rest[:rest_slice]\n\n    # VAL\n    test = rest[rest_slice:]\n\n    return train, test, val","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.000281Z","iopub.execute_input":"2022-03-30T10:44:16.000594Z","iopub.status.idle":"2022-03-30T10:44:16.006175Z","shell.execute_reply.started":"2022-03-30T10:44:16.000564Z","shell.execute_reply":"2022-03-30T10:44:16.005391Z"},"trusted":true},"execution_count":310,"outputs":[]},{"cell_type":"markdown","source":"## Tensorflow ","metadata":{}},{"cell_type":"markdown","source":"### Callbacks","metadata":{}},{"cell_type":"code","source":"class StopCallback(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get(\"accuracy\") or 0) > 0.99:\n            self.model.stop_training = True\n\nstop_callback = StopCallback()\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    CHECKPOINT,\n    monitor='val_accuracy',\n    save_best_only = True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.060561Z","iopub.execute_input":"2022-03-30T10:44:16.060874Z","iopub.status.idle":"2022-03-30T10:44:16.066193Z","shell.execute_reply.started":"2022-03-30T10:44:16.060844Z","shell.execute_reply":"2022-03-30T10:44:16.065411Z"},"trusted":true},"execution_count":311,"outputs":[]},{"cell_type":"code","source":"class TrackDataGen(keras.utils.Sequence):\n    \n    def __init__(self, data: List[Mfcc],\n                 target_f: Callable[[Track], Any],\n                 labels: LabelsJson,\n                 batch_size = BATCH_SIZE):\n        \n        self.batch_size = batch_size\n        X: List[np.ndarray] = []\n        Y: List[str] = []\n\n        for mfcc_ in data:\n            track = labels[\"tracks\"][mfcc_[\"track_id\"]]\n            target = target_f(track)\n            mfccs = mfcc_[\"mfccs\"]\n            \n            for split in mfccs:\n                X.append(split)\n                Y.append(target)\n\n        X_np = np.array(X)\n        X_np = np.expand_dims(X_np, axis=3)\n        Y_np = np.array(Y)\n\n        assert len(X_np) == len(Y_np)\n        self.X, self.Y = self.unison_shuffled_copies(X_np, Y_np)\n        \n    @staticmethod\n    def unison_shuffled_copies(a, b):\n        assert len(a) == len(b), f\"len(a) = {len(a)} != len(b) = {len(b)}\"\n        p = np.random.permutation(len(a))\n        return a[p], b[p]\n\n    def __getitem__(self, idx):\n        batch_x = self.X[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.Y[idx * self.batch_size:(idx + 1) * self.batch_size] \n        \n        return batch_x, np.array(batch_y)\n    \n    def __len__(self):\n        return len(self.X) // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.116382Z","iopub.execute_input":"2022-03-30T10:44:16.118262Z","iopub.status.idle":"2022-03-30T10:44:16.129347Z","shell.execute_reply.started":"2022-03-30T10:44:16.118217Z","shell.execute_reply":"2022-03-30T10:44:16.128534Z"},"trusted":true},"execution_count":312,"outputs":[]},{"cell_type":"code","source":"def build_network(type: Literal[\"multiclass\", \"multilabel\", \"mood\"], labels: int, shape: Tuple[int] = None):\n\n\n    if type == \"multilabel\":\n        activation, loss, metrics = \"sigmoid\", \"binary_crossentropy\", [\"categorical_accuracy\",]\n    elif type == \"mood\":\n        activation, loss, metrics = \"sigmoid\", \"sparse_categorical_crossentropy\", [\"categorical_accuracy\"]\n    elif type == \"multiclass\":\n        activation, loss, metrics = \"softmax\", \"sparse_categorical_crossentropy\", [\"accuracy\"]\n    else:\n        raise ValueError(\"Invalid Type\")\n    conv_base = keras.applications.EfficientNetB0(\n                    include_top = False, \n                    weights = \"imagenet\",\n                    drop_connect_rate=0.8)\n    conv_base.trainable = False\n    model = keras.models.Sequential([keras.layers.Conv2D(3,(3,3),padding='same', input_shape=shape), \n                                    conv_base, \n                                    keras.layers.GlobalAveragePooling2D(),\n                                    keras.layers.Dense(32, activation=\"relu\"),\n                                    keras.layers.Dense(labels, activation = activation)])\n    \n    model.compile(optimizer = \"adam\", loss = loss, metrics = metrics)\n    return model\n                                 ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.211735Z","iopub.execute_input":"2022-03-30T10:44:16.212418Z","iopub.status.idle":"2022-03-30T10:44:16.220704Z","shell.execute_reply.started":"2022-03-30T10:44:16.212381Z","shell.execute_reply":"2022-03-30T10:44:16.220002Z"},"trusted":true},"execution_count":313,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target Functions","metadata":{}},{"cell_type":"code","source":"def genre_target(t: Track, genres2labels: Dict[str, int]) -> int:\n    return genres2labels[t[\"genre\"][\"S\"]]\n\n\ndef mood_target(t: Track) -> List[float]:\n    default: N = {\"N\": 0.5}\n\n    acoustic = t.get(\"acoustic\") or default\n    aggressive = t.get(\"aggressive\") or default\n    electronic = t.get(\"electronic\") or default\n    happy = t.get(\"happy\") or default\n    party = t.get(\"party\") or default\n    relaxed = t.get(\"relaxed\") or default \n    sad = t.get(\"sad\") or default\n    return [acoustic[\"N\"], aggressive[\"N\"], electronic[\"N\"], happy[\"N\"], party[\"N\"], relaxed[\"N\"], sad[\"N\"]]\n\ndef subgenre_target(t: Track, subgenres: List[str]) -> List[Literal[1, 0]]:\n    track_subgenres = set([s[\"S\"] for s in t[\"subgenres\"][\"L\"]])\n    return [1 if sub in track_subgenres else 0 for sub in subgenres]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.310856Z","iopub.execute_input":"2022-03-30T10:44:16.311796Z","iopub.status.idle":"2022-03-30T10:44:16.322538Z","shell.execute_reply.started":"2022-03-30T10:44:16.311744Z","shell.execute_reply":"2022-03-30T10:44:16.321506Z"},"trusted":true},"execution_count":314,"outputs":[]},{"cell_type":"markdown","source":"## Main Function","metadata":{}},{"cell_type":"markdown","source":"#### Prepare the Data","metadata":{}},{"cell_type":"code","source":"labels: LabelsJson = load_json(LABELS) # type: ignore\n\n# Track Genres:\ngenres = list(set([t[\"genre\"][\"S\"] for t in labels[\"tracks\"].values()]))\ngenres2labels = {g: i for i,g in enumerate(genres)}\nlabels2genres = {i: g for i,g in enumerate(genres)}\n\n# Track Subgenres: \nsubgenres: Dict[str, List[str]] = load_json(SUBGENERES)\nsubgenre_list = list(subgenres.keys())\n\n# Get all subgenres:\nsubgenre_list = get_subgenres(\"pop\", subgenre_list)\nprint(f\"Subgenres: {subgenre_list}\")\n\n\n#subgen2labels = {g: i for i,g in enumerate(subgenre_list)}\n#labels2subgen = {i: g for i,g in enumerate(subgenre_list)}\n\ntarget_function = lambda t: subgenre_target(t, subgenre_list)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.367788Z","iopub.execute_input":"2022-03-30T10:44:16.368081Z","iopub.status.idle":"2022-03-30T10:44:16.988008Z","shell.execute_reply.started":"2022-03-30T10:44:16.368048Z","shell.execute_reply":"2022-03-30T10:44:16.987213Z"},"trusted":true},"execution_count":315,"outputs":[{"name":"stdout","text":"Subgenres: ['pop---indie pop', 'pop---europop', 'pop---ballad']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"rock: {genres2labels['rock']}\")\nprint(f\"pop: {genres2labels['pop']}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.989586Z","iopub.execute_input":"2022-03-30T10:44:16.990337Z","iopub.status.idle":"2022-03-30T10:44:16.995568Z","shell.execute_reply.started":"2022-03-30T10:44:16.990296Z","shell.execute_reply":"2022-03-30T10:44:16.994826Z"},"trusted":true},"execution_count":316,"outputs":[{"name":"stdout","text":"rock: 10\npop: 7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### Load the Data","metadata":{}},{"cell_type":"markdown","source":"#### Train the Model","metadata":{}},{"cell_type":"code","source":"mfccs = load_mfccs(subgenre_list, subgenres)\nrandom.shuffle(mfccs)\n\ntrain, test, val = train_test_val(mfccs)\n\nprint(f\"train {len(train)} + test {len(test)} + val {len(val)} = {len(train) + len(test) + len(val)}\" )\n\n# Initialize the dataset generators \ntrain_generator = TrackDataGen(train, target_function,  labels)\ntest_generator = TrackDataGen(test, target_function,  labels)\nvalidation_generator = TrackDataGen(val, target_function,  labels)\n\nshape = train_generator[0][0][0].shape\n\nprint(f\"shape: {shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:16.996692Z","iopub.execute_input":"2022-03-30T10:44:16.997342Z","iopub.status.idle":"2022-03-30T10:44:19.380755Z","shell.execute_reply.started":"2022-03-30T10:44:16.997300Z","shell.execute_reply":"2022-03-30T10:44:19.379960Z"},"trusted":true},"execution_count":317,"outputs":[{"name":"stdout","text":"train 735 + test 10 + val 186 = 931\nshape: (32, 130, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"type = \"multilabel\"\nlabels = len(subgenre_list)\n\nif type == \"multilabel\":\n    activation, loss, metrics = \"sigmoid\", \"binary_crossentropy\", [\"categorical_accuracy\",]\nelif type == \"mood\":\n    activation, loss, metrics = \"sigmoid\", \"sparse_categorical_crossentropy\", [\"categorical_accuracy\"]\nelif type == \"multiclass\":\n    activation, loss, metrics = \"softmax\", \"sparse_categorical_crossentropy\", [\"accuracy\"]\nelse:\n    raise ValueError(\"Invalid Type\")\nconv_base = keras.applications.EfficientNetB0(\n                include_top = False, \n                weights = \"imagenet\",\n                drop_connect_rate=0.8)\nconv_base.trainable = True\nmodel = keras.models.Sequential([keras.layers.Conv2D(3,(3,3),padding='same', input_shape=shape), \n                                conv_base, \n                                keras.layers.GlobalAveragePooling2D(),\n                                #keras.layers.Dense(64, activation=\"relu\"),\n\n                                #keras.layers.Dense(32, activation=\"relu\"),\n                                keras.layers.Dense(labels, activation = activation)])\n\nmodel.compile(optimizer = keras.optimizers.Adam(1e-5), loss = loss, metrics = metrics)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:19.383697Z","iopub.execute_input":"2022-03-30T10:44:19.384354Z","iopub.status.idle":"2022-03-30T10:44:21.575891Z","shell.execute_reply.started":"2022-03-30T10:44:19.384320Z","shell.execute_reply":"2022-03-30T10:44:21.575160Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"if False:\n    conv_base.trainable = True\n    model.compile(optimizer=keras.optimizers.Adam(1e-5), loss = loss, metrics = metrics)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:21.578200Z","iopub.execute_input":"2022-03-30T10:44:21.578592Z","iopub.status.idle":"2022-03-30T10:44:21.582983Z","shell.execute_reply.started":"2022-03-30T10:44:21.578556Z","shell.execute_reply":"2022-03-30T10:44:21.582319Z"},"trusted":true},"execution_count":319,"outputs":[]},{"cell_type":"code","source":"\n# Build and train the net \n#model = build_network(\"multilabel\", labels=len(subgenre_list), shape=shape )\nhistory = model.fit(train_generator,\n                    validation_data = validation_generator, \n                    epochs=200,\n                    callbacks = [stop_callback, checkpoint_callback],\n                    batch_size = BATCH_SIZE\n                )\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T10:44:21.584490Z","iopub.execute_input":"2022-03-30T10:44:21.584826Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/200\n268/268 [==============================] - 23s 57ms/step - loss: 0.7454 - categorical_accuracy: 0.3660 - val_loss: 0.6555 - val_categorical_accuracy: 0.4137\nEpoch 2/200\n268/268 [==============================] - 15s 55ms/step - loss: 0.7085 - categorical_accuracy: 0.3860 - val_loss: 0.6788 - val_categorical_accuracy: 0.4454\nEpoch 3/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.6838 - categorical_accuracy: 0.4233 - val_loss: 0.6653 - val_categorical_accuracy: 0.4561\nEpoch 4/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.6681 - categorical_accuracy: 0.4355 - val_loss: 0.6533 - val_categorical_accuracy: 0.4681\nEpoch 5/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.6578 - categorical_accuracy: 0.4330 - val_loss: 0.6447 - val_categorical_accuracy: 0.4734\nEpoch 6/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.6470 - categorical_accuracy: 0.4581 - val_loss: 0.6369 - val_categorical_accuracy: 0.4788\nEpoch 7/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.6405 - categorical_accuracy: 0.4570 - val_loss: 0.6329 - val_categorical_accuracy: 0.4866\nEpoch 8/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.6352 - categorical_accuracy: 0.4651 - val_loss: 0.6266 - val_categorical_accuracy: 0.4931\nEpoch 9/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.6282 - categorical_accuracy: 0.4758 - val_loss: 0.6210 - val_categorical_accuracy: 0.4943\nEpoch 10/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.6202 - categorical_accuracy: 0.4852 - val_loss: 0.6187 - val_categorical_accuracy: 0.5104\nEpoch 11/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.6156 - categorical_accuracy: 0.4981 - val_loss: 0.6162 - val_categorical_accuracy: 0.5140\nEpoch 12/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.6102 - categorical_accuracy: 0.5034 - val_loss: 0.6119 - val_categorical_accuracy: 0.5200\nEpoch 13/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.6044 - categorical_accuracy: 0.5112 - val_loss: 0.6101 - val_categorical_accuracy: 0.5212\nEpoch 14/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.6038 - categorical_accuracy: 0.5167 - val_loss: 0.6089 - val_categorical_accuracy: 0.5224\nEpoch 15/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5976 - categorical_accuracy: 0.5212 - val_loss: 0.6071 - val_categorical_accuracy: 0.5260\nEpoch 16/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.5966 - categorical_accuracy: 0.5178 - val_loss: 0.6042 - val_categorical_accuracy: 0.5248\nEpoch 17/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5911 - categorical_accuracy: 0.5251 - val_loss: 0.6035 - val_categorical_accuracy: 0.5307\nEpoch 18/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5857 - categorical_accuracy: 0.5428 - val_loss: 0.6012 - val_categorical_accuracy: 0.5361\nEpoch 19/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5813 - categorical_accuracy: 0.5385 - val_loss: 0.5992 - val_categorical_accuracy: 0.5367\nEpoch 20/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5761 - categorical_accuracy: 0.5434 - val_loss: 0.5986 - val_categorical_accuracy: 0.5403\nEpoch 21/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5723 - categorical_accuracy: 0.5567 - val_loss: 0.5987 - val_categorical_accuracy: 0.5367\nEpoch 22/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5778 - categorical_accuracy: 0.5496 - val_loss: 0.5966 - val_categorical_accuracy: 0.5367\nEpoch 23/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5647 - categorical_accuracy: 0.5567 - val_loss: 0.6001 - val_categorical_accuracy: 0.5367\nEpoch 24/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5636 - categorical_accuracy: 0.5666 - val_loss: 0.5978 - val_categorical_accuracy: 0.5433\nEpoch 25/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5631 - categorical_accuracy: 0.5622 - val_loss: 0.5949 - val_categorical_accuracy: 0.5409\nEpoch 26/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5583 - categorical_accuracy: 0.5725 - val_loss: 0.5967 - val_categorical_accuracy: 0.5379\nEpoch 27/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5571 - categorical_accuracy: 0.5728 - val_loss: 0.5953 - val_categorical_accuracy: 0.5528\nEpoch 28/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5468 - categorical_accuracy: 0.5872 - val_loss: 0.5925 - val_categorical_accuracy: 0.5540\nEpoch 29/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5468 - categorical_accuracy: 0.5812 - val_loss: 0.5927 - val_categorical_accuracy: 0.5528\nEpoch 30/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5450 - categorical_accuracy: 0.5846 - val_loss: 0.5918 - val_categorical_accuracy: 0.5540\nEpoch 31/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5394 - categorical_accuracy: 0.5976 - val_loss: 0.5937 - val_categorical_accuracy: 0.5582\nEpoch 32/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5377 - categorical_accuracy: 0.5901 - val_loss: 0.5937 - val_categorical_accuracy: 0.5606\nEpoch 33/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5373 - categorical_accuracy: 0.5912 - val_loss: 0.5906 - val_categorical_accuracy: 0.5588\nEpoch 34/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5297 - categorical_accuracy: 0.6010 - val_loss: 0.5914 - val_categorical_accuracy: 0.5588\nEpoch 35/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.5243 - categorical_accuracy: 0.6088 - val_loss: 0.5934 - val_categorical_accuracy: 0.5582\nEpoch 36/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5264 - categorical_accuracy: 0.6072 - val_loss: 0.5901 - val_categorical_accuracy: 0.5588\nEpoch 37/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5217 - categorical_accuracy: 0.6122 - val_loss: 0.5885 - val_categorical_accuracy: 0.5582\nEpoch 38/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5204 - categorical_accuracy: 0.6101 - val_loss: 0.5870 - val_categorical_accuracy: 0.5630\nEpoch 39/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5175 - categorical_accuracy: 0.6164 - val_loss: 0.5866 - val_categorical_accuracy: 0.5582\nEpoch 40/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.5128 - categorical_accuracy: 0.6194 - val_loss: 0.5887 - val_categorical_accuracy: 0.5642\nEpoch 41/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5102 - categorical_accuracy: 0.6234 - val_loss: 0.5918 - val_categorical_accuracy: 0.5672\nEpoch 42/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.5075 - categorical_accuracy: 0.6206 - val_loss: 0.5873 - val_categorical_accuracy: 0.5624\nEpoch 43/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.5073 - categorical_accuracy: 0.6204 - val_loss: 0.5879 - val_categorical_accuracy: 0.5642\nEpoch 44/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.5018 - categorical_accuracy: 0.6239 - val_loss: 0.5895 - val_categorical_accuracy: 0.5666\nEpoch 45/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4999 - categorical_accuracy: 0.6328 - val_loss: 0.5910 - val_categorical_accuracy: 0.5636\nEpoch 46/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.4961 - categorical_accuracy: 0.6337 - val_loss: 0.5907 - val_categorical_accuracy: 0.5660\nEpoch 47/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4955 - categorical_accuracy: 0.6324 - val_loss: 0.5899 - val_categorical_accuracy: 0.5678\nEpoch 48/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4901 - categorical_accuracy: 0.6399 - val_loss: 0.5909 - val_categorical_accuracy: 0.5696\nEpoch 49/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.4887 - categorical_accuracy: 0.6439 - val_loss: 0.5929 - val_categorical_accuracy: 0.5660\nEpoch 50/200\n268/268 [==============================] - 14s 50ms/step - loss: 0.4837 - categorical_accuracy: 0.6421 - val_loss: 0.5941 - val_categorical_accuracy: 0.5678\nEpoch 51/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.4795 - categorical_accuracy: 0.6469 - val_loss: 0.5952 - val_categorical_accuracy: 0.5678\nEpoch 52/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4732 - categorical_accuracy: 0.6563 - val_loss: 0.5962 - val_categorical_accuracy: 0.5648\nEpoch 53/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4784 - categorical_accuracy: 0.6488 - val_loss: 0.5981 - val_categorical_accuracy: 0.5594\nEpoch 54/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.4704 - categorical_accuracy: 0.6582 - val_loss: 0.5968 - val_categorical_accuracy: 0.5648\nEpoch 55/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4675 - categorical_accuracy: 0.6588 - val_loss: 0.6026 - val_categorical_accuracy: 0.5606\nEpoch 56/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4643 - categorical_accuracy: 0.6599 - val_loss: 0.5981 - val_categorical_accuracy: 0.5630\nEpoch 57/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4634 - categorical_accuracy: 0.6688 - val_loss: 0.5978 - val_categorical_accuracy: 0.5606\nEpoch 58/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4630 - categorical_accuracy: 0.6657 - val_loss: 0.6004 - val_categorical_accuracy: 0.5606\nEpoch 59/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4568 - categorical_accuracy: 0.6684 - val_loss: 0.6022 - val_categorical_accuracy: 0.5624\nEpoch 60/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4540 - categorical_accuracy: 0.6712 - val_loss: 0.6049 - val_categorical_accuracy: 0.5570\nEpoch 61/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.4502 - categorical_accuracy: 0.6728 - val_loss: 0.6065 - val_categorical_accuracy: 0.5630\nEpoch 62/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4460 - categorical_accuracy: 0.6788 - val_loss: 0.6107 - val_categorical_accuracy: 0.5570\nEpoch 63/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.4459 - categorical_accuracy: 0.6843 - val_loss: 0.6103 - val_categorical_accuracy: 0.5594\nEpoch 64/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4452 - categorical_accuracy: 0.6782 - val_loss: 0.6131 - val_categorical_accuracy: 0.5570\nEpoch 65/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.4391 - categorical_accuracy: 0.6860 - val_loss: 0.6128 - val_categorical_accuracy: 0.5522\nEpoch 66/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4381 - categorical_accuracy: 0.6821 - val_loss: 0.6160 - val_categorical_accuracy: 0.5570\nEpoch 67/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4377 - categorical_accuracy: 0.6797 - val_loss: 0.6139 - val_categorical_accuracy: 0.5606\nEpoch 68/200\n268/268 [==============================] - 15s 55ms/step - loss: 0.4331 - categorical_accuracy: 0.6936 - val_loss: 0.6178 - val_categorical_accuracy: 0.5588\nEpoch 69/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4295 - categorical_accuracy: 0.6949 - val_loss: 0.6216 - val_categorical_accuracy: 0.5564\nEpoch 70/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4234 - categorical_accuracy: 0.6940 - val_loss: 0.6224 - val_categorical_accuracy: 0.5570\nEpoch 71/200\n268/268 [==============================] - 13s 49ms/step - loss: 0.4242 - categorical_accuracy: 0.7016 - val_loss: 0.6254 - val_categorical_accuracy: 0.5540\nEpoch 72/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.4211 - categorical_accuracy: 0.6984 - val_loss: 0.6271 - val_categorical_accuracy: 0.5576\nEpoch 73/200\n268/268 [==============================] - 13s 49ms/step - loss: 0.4160 - categorical_accuracy: 0.7030 - val_loss: 0.6283 - val_categorical_accuracy: 0.5570\nEpoch 74/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4139 - categorical_accuracy: 0.7109 - val_loss: 0.6320 - val_categorical_accuracy: 0.5546\nEpoch 75/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.4096 - categorical_accuracy: 0.7104 - val_loss: 0.6322 - val_categorical_accuracy: 0.5528\nEpoch 76/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4053 - categorical_accuracy: 0.7176 - val_loss: 0.6358 - val_categorical_accuracy: 0.5546\nEpoch 77/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.4028 - categorical_accuracy: 0.7163 - val_loss: 0.6389 - val_categorical_accuracy: 0.5564\nEpoch 78/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4036 - categorical_accuracy: 0.7091 - val_loss: 0.6362 - val_categorical_accuracy: 0.5582\nEpoch 79/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3958 - categorical_accuracy: 0.7228 - val_loss: 0.6390 - val_categorical_accuracy: 0.5588\nEpoch 80/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.4009 - categorical_accuracy: 0.7158 - val_loss: 0.6403 - val_categorical_accuracy: 0.5576\nEpoch 81/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3924 - categorical_accuracy: 0.7310 - val_loss: 0.6385 - val_categorical_accuracy: 0.5576\nEpoch 82/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3878 - categorical_accuracy: 0.7248 - val_loss: 0.6467 - val_categorical_accuracy: 0.5570\nEpoch 83/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3863 - categorical_accuracy: 0.7328 - val_loss: 0.6494 - val_categorical_accuracy: 0.5582\nEpoch 84/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3859 - categorical_accuracy: 0.7300 - val_loss: 0.6520 - val_categorical_accuracy: 0.5552\nEpoch 85/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3820 - categorical_accuracy: 0.7355 - val_loss: 0.6555 - val_categorical_accuracy: 0.5570\nEpoch 86/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3808 - categorical_accuracy: 0.7333 - val_loss: 0.6525 - val_categorical_accuracy: 0.5558\nEpoch 87/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3727 - categorical_accuracy: 0.7433 - val_loss: 0.6579 - val_categorical_accuracy: 0.5528\nEpoch 88/200\n268/268 [==============================] - 15s 54ms/step - loss: 0.3738 - categorical_accuracy: 0.7370 - val_loss: 0.6599 - val_categorical_accuracy: 0.5546\nEpoch 89/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3675 - categorical_accuracy: 0.7443 - val_loss: 0.6650 - val_categorical_accuracy: 0.5481\nEpoch 90/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3630 - categorical_accuracy: 0.7445 - val_loss: 0.6667 - val_categorical_accuracy: 0.5534\nEpoch 91/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3640 - categorical_accuracy: 0.7436 - val_loss: 0.6769 - val_categorical_accuracy: 0.5510\nEpoch 92/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3569 - categorical_accuracy: 0.7500 - val_loss: 0.6800 - val_categorical_accuracy: 0.5487\nEpoch 93/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3577 - categorical_accuracy: 0.7494 - val_loss: 0.6823 - val_categorical_accuracy: 0.5564\nEpoch 94/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3537 - categorical_accuracy: 0.7600 - val_loss: 0.6803 - val_categorical_accuracy: 0.5564\nEpoch 95/200\n268/268 [==============================] - 15s 55ms/step - loss: 0.3525 - categorical_accuracy: 0.7545 - val_loss: 0.6874 - val_categorical_accuracy: 0.5504\nEpoch 96/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3468 - categorical_accuracy: 0.7604 - val_loss: 0.6877 - val_categorical_accuracy: 0.5552\nEpoch 97/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3401 - categorical_accuracy: 0.7675 - val_loss: 0.6930 - val_categorical_accuracy: 0.5469\nEpoch 98/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3358 - categorical_accuracy: 0.7672 - val_loss: 0.7013 - val_categorical_accuracy: 0.5510\nEpoch 99/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3420 - categorical_accuracy: 0.7631 - val_loss: 0.7020 - val_categorical_accuracy: 0.5516\nEpoch 100/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3346 - categorical_accuracy: 0.7682 - val_loss: 0.7066 - val_categorical_accuracy: 0.5528\nEpoch 101/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.3341 - categorical_accuracy: 0.7699 - val_loss: 0.7109 - val_categorical_accuracy: 0.5499\nEpoch 102/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3330 - categorical_accuracy: 0.7688 - val_loss: 0.7208 - val_categorical_accuracy: 0.5463\nEpoch 103/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3251 - categorical_accuracy: 0.7791 - val_loss: 0.7177 - val_categorical_accuracy: 0.5481\nEpoch 104/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3250 - categorical_accuracy: 0.7719 - val_loss: 0.7191 - val_categorical_accuracy: 0.5504\nEpoch 105/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3258 - categorical_accuracy: 0.7751 - val_loss: 0.7185 - val_categorical_accuracy: 0.5504\nEpoch 106/200\n268/268 [==============================] - 14s 53ms/step - loss: 0.3155 - categorical_accuracy: 0.7863 - val_loss: 0.7284 - val_categorical_accuracy: 0.5522\nEpoch 107/200\n268/268 [==============================] - 14s 52ms/step - loss: 0.3184 - categorical_accuracy: 0.7812 - val_loss: 0.7296 - val_categorical_accuracy: 0.5481\nEpoch 108/200\n268/268 [==============================] - 14s 54ms/step - loss: 0.3104 - categorical_accuracy: 0.7849 - val_loss: 0.7376 - val_categorical_accuracy: 0.5499\nEpoch 109/200\n268/268 [==============================] - 14s 51ms/step - loss: 0.3089 - categorical_accuracy: 0.7942 - val_loss: 0.7367 - val_categorical_accuracy: 0.5463\nEpoch 110/200\n228/268 [========================>.....] - ETA: 1s - loss: 0.3092 - categorical_accuracy: 0.7951","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"final.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analyze the Results ","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef plot_history(history):\n    # plot accuracy+\n\n\n    # plot categorical accuracy\n    plt.plot(history.history['categorical_accuracy'])\n    plt.plot(history.history['val_categorical_accuracy'])\n\n    plt.plot(history.history['loss'], label='train')\n    plt.plot(history.history['val_loss'], label='test')\n    plt.legend()\n    plt.show()\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport json\nimport random as random_\nimport re\nfrom glob import iglob\nimport os\nfrom typing import List, Dict, Tuple, Set, Any,  Union, Optional, Callable\nfrom typing_extensions import TypedDict, Literal\nfrom math import floor\nimport pandas as pd\nimport seaborn\nimport matplotlib.pyplot as plt \nfrom pprint import pprint\nfrom sklearn.preprocessing import normalize\nfrom time import time","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:40.018401Z","iopub.execute_input":"2022-04-18T08:20:40.019204Z","iopub.status.idle":"2022-04-18T08:20:41.919924Z","shell.execute_reply.started":"2022-04-18T08:20:40.019100Z","shell.execute_reply":"2022-04-18T08:20:41.919162Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#!pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:41.922863Z","iopub.execute_input":"2022-04-18T08:20:41.923117Z","iopub.status.idle":"2022-04-18T08:20:41.926207Z","shell.execute_reply.started":"2022-04-18T08:20:41.923084Z","shell.execute_reply":"2022-04-18T08:20:41.925557Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"https://datascience.stackexchange.com/questions/43191/validation-loss-is-not-decreasing","metadata":{}},{"cell_type":"code","source":"print(tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:41.927388Z","iopub.execute_input":"2022-04-18T08:20:41.927790Z","iopub.status.idle":"2022-04-18T08:20:41.985428Z","shell.execute_reply.started":"2022-04-18T08:20:41.927755Z","shell.execute_reply":"2022-04-18T08:20:41.984636Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2.6.2\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"},{"name":"stderr","text":"2022-04-18 08:20:41.969328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:20:41.979505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:20:41.980312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","output_type":"stream"}]},{"cell_type":"code","source":"DATASET_BASE = \"../input/ludwig-music-dataset-moods-and-subgenres\"\nMFCCS  = f\"{DATASET_BASE}/mfccs\"\nLABELS = f\"{DATASET_BASE}/labels.json\"\nSUBGENERES = f\"{DATASET_BASE}/subgeneres.json\"\nCHECKPOINT = \"./checkpoint/saved_model.h5\"\nBATCH_SIZE = 26\n\nSEED = random_.randint(0, 100)\nrandom = random_.Random(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:41.988259Z","iopub.execute_input":"2022-04-18T08:20:41.988919Z","iopub.status.idle":"2022-04-18T08:20:41.996061Z","shell.execute_reply.started":"2022-04-18T08:20:41.988871Z","shell.execute_reply":"2022-04-18T08:20:41.995086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## JSON Declaration and other Dicts ","metadata":{}},{"cell_type":"code","source":"\n\nclass N(TypedDict): # A number \n    N: Union[float, int]\n\nclass S(TypedDict): # A string\n    S: str\n\nclass L(TypedDict): # A list of strings\n    L: List[S]\n\nclass Track(TypedDict):\n    # IDs\n    PK: S\n    mbid: S\n\n    # Genres: \n    genre: S\n    subgenres: L\n    otherSubgenres: Optional[L]\n\n    # Moods\n    aggressive: Optional[N]\n    happy: Optional[N]\n    party: Optional[N]\n    acoustic: Optional[N] \n    electronic: Optional[N]\n    sad: Optional[N]\n    relaxed: Optional[N]\n\n    # Metadata\n    preview: S\n    name: Optional[S]\n    artist: Optional[S]\n    popularity: Optional[N]\n    album: Optional[S]\n    \n\nclass LabelsJson(TypedDict):\n    tracks: Dict[str, Track]\n\nclass Mfcc(TypedDict):\n    mfccs: np.ndarray\n    track_id: str\n    splits: int\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:41.997459Z","iopub.execute_input":"2022-04-18T08:20:41.998082Z","iopub.status.idle":"2022-04-18T08:20:42.010098Z","shell.execute_reply.started":"2022-04-18T08:20:41.998038Z","shell.execute_reply":"2022-04-18T08:20:42.008805Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_json(path:str) -> Dict[str, Any]:\n    \"\"\"Loads a json file \n\n    Args:\n        path (str): json file path\n\n    Returns:\n        Dict: A dictionary indexed by a string\n    \"\"\"\n    with open(path, \"r\") as f:\n        return json.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.012073Z","iopub.execute_input":"2022-04-18T08:20:42.012620Z","iopub.status.idle":"2022-04-18T08:20:42.020651Z","shell.execute_reply.started":"2022-04-18T08:20:42.012574Z","shell.execute_reply":"2022-04-18T08:20:42.019616Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def get_subgenres(parent_genre: str, subgenres: List[str]):\n    \"\"\"Get all subgenres of a given genre\n\n    Args:\n        parent_genre (str): \n        subgenres (List[str]): List of subgenres to match with a parent genre\n\n    Returns:\n        List[str]: List of subgenres\n    \"\"\"\n    return list(filter(lambda s: parent_genre in s.split(\"---\")[0] ,subgenres))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.022350Z","iopub.execute_input":"2022-04-18T08:20:42.022671Z","iopub.status.idle":"2022-04-18T08:20:42.029825Z","shell.execute_reply.started":"2022-04-18T08:20:42.022629Z","shell.execute_reply":"2022-04-18T08:20:42.028889Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_mfccs(subgenres_list: List[str], subgenres: Dict[str, List[str]], labels: LabelsJson, search_path: str = MFCCS,  max_per_genre = None):\n    \n    track_set: Set[str] = set() # List of track ids among all subgenres_list subgenres\n    \n    genre_count: Dict[str, int] = {}\n    \n    track_splits: List[Mfcc] = [] \n\n    for g in subgenres_list:\n        track_set.update(subgenres[g])\n\n    for npy in iglob(search_path + '/**/*.npy', recursive=True):\n        match = re.search(r\"[a-zA-Z0-9]+.npy\", npy)\n\n        if (match and match.group(0)):\n            track_id = match.group(0).replace(\".npy\", \"\")\n            if track_id in track_set: \n                genre = labels[\"tracks\"][track_id][\"genre\"][\"S\"]\n                g_count = genre_count.get(genre, 0)\n                \n                if max_per_genre is not None and g_count > max_per_genre:\n                    continue\n                \n                try:\n                    mfccs_splits = np.load(npy)\n                    track_splits.append({\"mfccs\": mfccs_splits, \"track_id\": track_id, \"splits\": len(mfccs_splits)})\n                    genre_count[genre] = g_count + 1\n                except IOError:\n                    print(f\"File {npy} not found\")\n\n    return track_splits\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.031490Z","iopub.execute_input":"2022-04-18T08:20:42.031978Z","iopub.status.idle":"2022-04-18T08:20:42.044716Z","shell.execute_reply.started":"2022-04-18T08:20:42.031936Z","shell.execute_reply":"2022-04-18T08:20:42.043827Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def normalize_data(data):\n    return np.subtract(data,np.mean(data))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.046145Z","iopub.execute_input":"2022-04-18T08:20:42.046667Z","iopub.status.idle":"2022-04-18T08:20:42.058128Z","shell.execute_reply.started":"2022-04-18T08:20:42.046624Z","shell.execute_reply":"2022-04-18T08:20:42.057252Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train_test_val(ds: List[Mfcc], test=0.01, val=0.2):\n    # TRAIN     \n    train_slice = floor(len(ds) * (1 - val - test))\n    train = ds[:train_slice]\n\n    rest = ds[train_slice:]\n    rest_slice =  floor(len(rest) * (1 - (test / ( test + val))))\n\n    # TEST\n    val = rest[:rest_slice]\n\n    # VAL\n    test = rest[rest_slice:]\n\n    return train, test, val","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.062749Z","iopub.execute_input":"2022-04-18T08:20:42.063066Z","iopub.status.idle":"2022-04-18T08:20:42.070915Z","shell.execute_reply.started":"2022-04-18T08:20:42.063025Z","shell.execute_reply":"2022-04-18T08:20:42.069197Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Tensorflow ","metadata":{}},{"cell_type":"markdown","source":"### Callbacks","metadata":{}},{"cell_type":"code","source":"class StopCallback(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get(\"accuracy\") or 0) > 0.99:\n            self.model.stop_training = True\n\nstop_callback = StopCallback()\n\n\ndef build_checkpoint_callback(out_file = CHECKPOINT):\n    return tf.keras.callbacks.ModelCheckpoint(\n        out_file,\n        monitor='val_accuracy',\n        save_best_only = True,\n        verbose = True,\n\n    )\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.072898Z","iopub.execute_input":"2022-04-18T08:20:42.073592Z","iopub.status.idle":"2022-04-18T08:20:42.261112Z","shell.execute_reply.started":"2022-04-18T08:20:42.073525Z","shell.execute_reply":"2022-04-18T08:20:42.260312Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"target_dict = {\"a\": [1,2,3], \"b\": [2, 1]}\nprint(min([len(x) for x in target_dict.values()]))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.262330Z","iopub.execute_input":"2022-04-18T08:20:42.262639Z","iopub.status.idle":"2022-04-18T08:20:42.270265Z","shell.execute_reply.started":"2022-04-18T08:20:42.262600Z","shell.execute_reply":"2022-04-18T08:20:42.269502Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"class TrackDataGen(keras.utils.Sequence):\n    \n    def __init__(self, data: List[Mfcc],\n                 target_f: Callable[[Track], Any],\n                 labels: LabelsJson,\n                 undersample = False,\n                 oversample = False,\n                 verbose = False,\n                 filter = lambda t: True,\n                 batch_size = BATCH_SIZE):\n        \n        self.batch_size = batch_size\n        target_dict = {}\n        X: List[np.ndarray] = []\n        Y: List[str] = []\n\n        for mfcc_ in data:\n            track = labels[\"tracks\"][mfcc_[\"track_id\"]]\n            \n            if filter(track):\n                target = target_f(track)\n                mfccs = mfcc_[\"mfccs\"]\n                target_list = target_dict.get(str(target), [])\n                for split in mfccs:\n                    target_list.append([split, target])\n                target_dict[str(target)] = target_list\n        \n\n        if verbose:\n            print(\"Items Per Label:\")\n            for target, splits in target_dict.items():\n                print(f\"{target}: {len(splits)}\")\n            \n        \n        if undersample:\n            limit = min([len(x) for x in target_dict.values()])\n        elif oversample:\n            limit = max([len(x) for x in target_dict.values()])\n            \n        else:\n            limit = None\n            \n        for splits in target_dict.values():\n            for split in splits[:limit]:\n                X.append(split[0])\n                Y.append(split[1])\n            \n            if oversample: \n                missing = limit - len(splits)\n                \n                oversample_candidates = list(splits)\n                \n                while len(oversample_candidates) < missing:\n                    oversample_candidates.extend(list(splits))\n                    \n                random.shuffle(oversample_candidates)\n                \n                extra =  oversample_candidates[:missing]\n                \n                for value, tag in extra:\n                    X.append(value)\n                    Y.append(tag)\n                    \n\n        X_np = np.array(X)\n        X_np = np.expand_dims(X_np, axis=3)\n        Y_np = np.array(Y)\n\n        if verbose:\n            print(f\"X shape: {X_np.shape} X dtype: {X_np.dtype} Y shape: {Y_np.shape} Y dtype: {Y_np.dtype}\") \n\n        assert len(X_np) == len(Y_np)\n        self.X, self.Y = self.unison_shuffled_copies(normalize_data(X_np), Y_np)\n        \n    @staticmethod\n    def unison_shuffled_copies(a, b):\n        assert len(a) == len(b), f\"len(a) = {len(a)} != len(b) = {len(b)}\"\n        p = np.random.permutation(len(a))\n        return a[p], b[p]\n\n    def __getitem__(self, idx):\n        batch_x = self.X[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.Y[idx * self.batch_size:(idx + 1) * self.batch_size] \n        \n        return batch_x, np.array(batch_y)\n    \n    def to_numpy(self):\n        return self.X, self.Y\n    def __len__(self):\n        return len(self.X) // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.271618Z","iopub.execute_input":"2022-04-18T08:20:42.272134Z","iopub.status.idle":"2022-04-18T08:20:42.295340Z","shell.execute_reply.started":"2022-04-18T08:20:42.272091Z","shell.execute_reply":"2022-04-18T08:20:42.294428Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target Functions","metadata":{}},{"cell_type":"code","source":"def genre_target(t: Track, genres2labels: Dict[str, int]) -> int:\n    return genres2labels[t[\"genre\"][\"S\"]]\n\n\ndef binary_genre_target(t: Track, genre: str):\n    for sub in t[\"subgenres\"][\"L\"] + t[\"otherSubgenres\"][\"L\"]:\n        if genre in sub[\"S\"].split(\"---\")[0]:\n            return 1\n    return 0\n\ndef mood_target(t: Track) -> List[float]:\n    default: N = {\"N\": 0.5}\n\n    acoustic =  (t.get(\"acoustic\") or default)\n    aggressive = t.get(\"aggressive\") or default\n    electronic = t.get(\"electronic\") or default\n    happy = t.get(\"happy\") or default\n    party = t.get(\"party\") or default\n    relaxed = t.get(\"relaxed\") or default \n    sad = t.get(\"sad\") or default\n    return [1 if float(prob) > 0.5 else 0 for prob in [acoustic[\"N\"], aggressive[\"N\"], electronic[\"N\"], happy[\"N\"], party[\"N\"], relaxed[\"N\"], sad[\"N\"]]]\n\ndef subgenre_target(t: Track, subgenres: List[str]) -> List[Literal[1, 0]]:\n    track_subgenres = set([s[\"S\"] for s in t[\"subgenres\"][\"L\"]])\n    return [1 if sub in track_subgenres else 0 for sub in subgenres]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.296801Z","iopub.execute_input":"2022-04-18T08:20:42.297537Z","iopub.status.idle":"2022-04-18T08:20:42.310893Z","shell.execute_reply.started":"2022-04-18T08:20:42.297475Z","shell.execute_reply":"2022-04-18T08:20:42.310134Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_track_labels(track_id):\n    track = labels[\"tracks\"][track_id]\n    return target_function(track)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.312175Z","iopub.execute_input":"2022-04-18T08:20:42.312995Z","iopub.status.idle":"2022-04-18T08:20:42.320988Z","shell.execute_reply.started":"2022-04-18T08:20:42.312953Z","shell.execute_reply":"2022-04-18T08:20:42.320131Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_resnet18():\n    if not os.path.exists(\"resnet18.h5\"):\n        !wget https://github.com/breadbread1984/resnet18-34/raw/master/models/resnet18.h5\n    \n    return keras.models.load_model(\"resnet18.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.324161Z","iopub.execute_input":"2022-04-18T08:20:42.324576Z","iopub.status.idle":"2022-04-18T08:20:42.332368Z","shell.execute_reply.started":"2022-04-18T08:20:42.324352Z","shell.execute_reply":"2022-04-18T08:20:42.331557Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_gtzan():\n    if not os.path.exists(\"gtzan_ext.h5\"):\n        !wget https://github.com/JorgeRuizDev/SpotMyFM/raw/main/Ludwig/models/gtzan_ext.h5\n    \n    return keras.models.load_model(\"gtzan_ext.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.333680Z","iopub.execute_input":"2022-04-18T08:20:42.334014Z","iopub.status.idle":"2022-04-18T08:20:42.340621Z","shell.execute_reply.started":"2022-04-18T08:20:42.333975Z","shell.execute_reply":"2022-04-18T08:20:42.339761Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def build_CNN(label_count: int, activation: str, input_shape: Tuple[int], name=\"Sequential\"):\n    model = keras.models.Sequential([\n        #keras.layers.Normalization(axis=-1, input_shape=shape),\n        keras.Input(shape=shape),\n        keras.layers.Conv2D(4, (3,3), activation=\"relu\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.MaxPooling2D(2, 2),\n        keras.layers.BatchNormalization(),\n\n        keras.layers.Conv2D(8, (3,3), activation=\"relu\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.MaxPooling2D(2, 2),\n        keras.layers.BatchNormalization(),\n        \n        keras.layers.Conv2D(16, (3,3), activation=\"relu\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.MaxPooling2D(2, 2),\n        keras.layers.BatchNormalization(),\n\n\n        keras.layers.Flatten(),\n\n\n        keras.layers.Dropout(0.3),\n\n        keras.layers.Dense(256, activation=\"relu\"),\n        keras.layers.Dropout(0.1),\n\n        #keras.layers.Dense(64, activation=\"relu\"),\n        keras.layers.Dense(label_count , activation=activation),  \n    ])\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.342035Z","iopub.execute_input":"2022-04-18T08:20:42.342887Z","iopub.status.idle":"2022-04-18T08:20:42.354937Z","shell.execute_reply.started":"2022-04-18T08:20:42.342845Z","shell.execute_reply":"2022-04-18T08:20:42.354214Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef plot_history(history):\n    # plot accuracy\n    if not history:\n        return\n\n    # plot categorical accuracy\n    plt.plot(history.history[metrics[0]])\n    plt.plot(history.history[f'val_{metrics[0]}'])\n\n    \n    plt.plot(history.history['loss'], label='train', marker=\"+\" )\n    plt.plot(history.history['val_loss'], label='test', marker=\"+\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.356348Z","iopub.execute_input":"2022-04-18T08:20:42.356861Z","iopub.status.idle":"2022-04-18T08:20:42.368079Z","shell.execute_reply.started":"2022-04-18T08:20:42.356823Z","shell.execute_reply":"2022-04-18T08:20:42.367375Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def one_gen_per_track_filer(t: Track):\n    genres = set()\n    \n    for sub in t[\"subgenres\"][\"L\"] + t[\"otherSubgenres\"][\"L\"]:\n        genre = sub[\"S\"].split(\"---\")[0]\n        genres.add(genre)\n    \n    return True if len(genres) == 1 else False","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.369903Z","iopub.execute_input":"2022-04-18T08:20:42.370537Z","iopub.status.idle":"2022-04-18T08:20:42.377052Z","shell.execute_reply.started":"2022-04-18T08:20:42.370484Z","shell.execute_reply":"2022-04-18T08:20:42.376236Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def filder_moods(t: Track):\n    return True if t[\"happy\"] is not None and t[\"happy\"][\"N\"] is not None else False","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.378695Z","iopub.execute_input":"2022-04-18T08:20:42.378962Z","iopub.status.idle":"2022-04-18T08:20:42.385699Z","shell.execute_reply.started":"2022-04-18T08:20:42.378927Z","shell.execute_reply":"2022-04-18T08:20:42.384931Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"moods_names = [\"happy\", \"sad\", \"party\", \"relaxed\", \"acoustic\", \"electronic\", \"aggressive\"]\n\ndef build_mood_ova(labels: LabelsJson, train: List[Mfcc], val: List[Mfcc], moods_names = moods_names):\n    models = []\n\n    \n\n    for i, mood_name in enumerate(moods_names):\n        checkpoint_file = f\"./mood-ova/{mood_name}\"\n        \n        target_fn = lambda t: 1 if float(t[mood_name][\"N\"]) > 0.5 else 0\n        filter_fn = lambda t: True if t[mood_name] is not None and (float(t[mood_name][\"N\"]) > 2/3 or float(t[mood_name][\"N\"]) < 1/3) else False\n        \n        # Prepare the Data + Binary Label\n        train_generator = TrackDataGen(train, target_fn,  labels, undersample=True, verbose=True, filter = filter_fn )\n        \n        validation_generator = TrackDataGen(val, target_fn,  labels, undersample=True, filter = filder_moods)\n        \n        shape = train_generator[0][0][0].shape\n        \n        model = build_CNN(1, \"sigmoid\", input_shape=shape)\n        checkpoint_callback = build_checkpoint_callback(checkpoint_file)\n        model.compile(optimizer = keras.optimizers.Adam(), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n        \n        history = model.fit(train_generator,\n            validation_data = validation_generator, \n            epochs=30,\n            callbacks = [stop_callback, checkpoint_callback],\n            batch_size = BATCH_SIZE\n        )\n\n        loaded_model = keras.models.load_model(checkpoint_file)\n        del validation_generator\n        del train_generator\n        del model\n        if history is not None:\n            plot_history(history)\n        \n\n        models.append((mood_name, loaded_model))\n    return models\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.387915Z","iopub.execute_input":"2022-04-18T08:20:42.388788Z","iopub.status.idle":"2022-04-18T08:20:42.400374Z","shell.execute_reply.started":"2022-04-18T08:20:42.388747Z","shell.execute_reply":"2022-04-18T08:20:42.399637Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def build_ova(genres: List[str], labels: LabelsJson, train: List[Mfcc], val: List[Mfcc]):\n    \n    models = []\n    for i, genre in enumerate(genres):\n        print(f\"Training {genre}\")\n        checkpoint_file = f\"./ova/{i}-{genre}.h5\"\n        \n             \n        # Prepare the Data + Binary Label\n        train_generator = TrackDataGen(train, lambda x: binary_genre_target(x, genre),  labels, oversample=True, verbose=True, filter = one_gen_per_track_filer )\n        \n        validation_generator = TrackDataGen(val, lambda x: binary_genre_target(x, genre),  labels, undersample=True, filter = one_gen_per_track_filer),\n        \n        shape = train_generator[0][0][0].shape\n    \n        \n        model = build_CNN(1, \"sigmoid\", input_shape=shape,name=genre)\n        checkpoint_callback = build_checkpoint_callback(checkpoint_file)\n        model.compile(optimizer = keras.optimizers.Adam(), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n\n        \n        history = model.fit(train_generator,\n                    validation_data = validation_generator, \n                    epochs=50,\n                    callbacks = [stop_callback, checkpoint_callback],\n                    batch_size = BATCH_SIZE\n                )\n\n        loaded_model = keras.models.load_model(checkpoint_file)\n        del validation_generator\n        del train_generator\n        del model\n        if history is not None:\n            plot_history(history)\n        \n\n        models.append((genre, loaded_model ))\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.402675Z","iopub.execute_input":"2022-04-18T08:20:42.404159Z","iopub.status.idle":"2022-04-18T08:20:42.415552Z","shell.execute_reply.started":"2022-04-18T08:20:42.404128Z","shell.execute_reply":"2022-04-18T08:20:42.414856Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Main Function","metadata":{}},{"cell_type":"markdown","source":"#### Prepare the Data","metadata":{}},{"cell_type":"code","source":"labels: LabelsJson = load_json(LABELS) # type: ignore\n\n# Track Genres:\ngenres = list(set([t[\"genre\"][\"S\"] for t in labels[\"tracks\"].values()]))\ngenres2labels = {g: i for i,g in enumerate(genres)}\nlabels2genres = {i: g for i,g in enumerate(genres)}\n# Track Subgenres: \nsubgenres: Dict[str, List[str]] = load_json(SUBGENERES)\nsubgenre_list = list(subgenres.keys())\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:42.418077Z","iopub.execute_input":"2022-04-18T08:20:42.418258Z","iopub.status.idle":"2022-04-18T08:20:43.459461Z","shell.execute_reply.started":"2022-04-18T08:20:42.418235Z","shell.execute_reply":"2022-04-18T08:20:43.458723Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"pprint(genres2labels)\npprint(labels2genres)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:43.460569Z","iopub.execute_input":"2022-04-18T08:20:43.460845Z","iopub.status.idle":"2022-04-18T08:20:43.471804Z","shell.execute_reply.started":"2022-04-18T08:20:43.460808Z","shell.execute_reply":"2022-04-18T08:20:43.470896Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'blues': 2,\n 'classical': 5,\n 'electronic': 8,\n 'funk / soul': 6,\n 'hip hop': 0,\n 'jazz': 7,\n 'latin': 3,\n 'pop': 1,\n 'rock': 4}\n{0: 'hip hop',\n 1: 'pop',\n 2: 'blues',\n 3: 'latin',\n 4: 'rock',\n 5: 'classical',\n 6: 'funk / soul',\n 7: 'jazz',\n 8: 'electronic'}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"All Subgenres: \")\ngenre_sub = {}\nfor s in subgenre_list:\n    main = s.split(\"---\")[0]\n    subgenres_ = genre_sub.get(main, [])\n    subgenres_.append(s)\n    genre_sub[main] = subgenres_\n    \npprint(genre_sub)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:43.474063Z","iopub.execute_input":"2022-04-18T08:20:43.474456Z","iopub.status.idle":"2022-04-18T08:20:43.490683Z","shell.execute_reply.started":"2022-04-18T08:20:43.474420Z","shell.execute_reply":"2022-04-18T08:20:43.487150Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"All Subgenres: \n{'blues': ['blues---country blues', 'blues---electric blues'],\n 'classical': ['classical---classical',\n               'classical---romantic',\n               'classical---baroque',\n               'classical---modern',\n               'classical---opera'],\n 'electronic': ['electronic---ambient',\n                'electronic---synth-pop',\n                'electronic---disco',\n                'electronic---house',\n                'electronic---drum n bass',\n                'electronic---downtempo',\n                'electronic---new wave',\n                'electronic---electro',\n                'electronic---trip hop'],\n 'funk / soul': ['funk / soul---disco',\n                 'funk / soul---rhythm & blues',\n                 'funk / soul---soul'],\n 'hip hop': ['hip hop---trap',\n             'hip hop---pop rap',\n             'hip hop---instrumental',\n             'hip hop---conscious',\n             'hip hop---trip hop',\n             'hip hop---gangsta'],\n 'jazz': ['jazz---contemporary jazz', 'jazz---swing', 'jazz---soul-jazz'],\n 'latin': ['latin---reggaeton',\n           'latin---salsa',\n           'latin---reggae',\n           'latin---flamenco',\n           'latin---samba',\n           'latin---cubano'],\n 'pop': ['pop---indie pop', 'pop---europop', 'pop---ballad'],\n 'rock': ['rock---pop rock',\n          'rock---prog rock',\n          'rock---punk',\n          'rock---alternative rock',\n          'rock---heavy metal',\n          'rock---hard rock',\n          'rock---nu metal',\n          'rock---death metal',\n          'rock---goth rock',\n          'rock---post rock',\n          'rock---shoegaze',\n          'rock---art rock',\n          'rock---post-punk',\n          'rock---new wave',\n          'rock---viking metal']}\n","output_type":"stream"}]},{"cell_type":"code","source":"subgenre_set = set()\nfor s in [get_subgenres(g, subgenre_list) for g in [\"jazz\", \"blues\", \"pop\", \"funk / soul\", \"rock\", \"electronic\", \"hip hop\"]]:\n    subgenre_set.update(s)\n\n#subgenre_list = list(subgenre_set)\n\n#subgenre_list = get_subgenres(\"electronic\", subgenre_list)\nprint(subgenre_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:43.491929Z","iopub.execute_input":"2022-04-18T08:20:43.492163Z","iopub.status.idle":"2022-04-18T08:20:43.497946Z","shell.execute_reply.started":"2022-04-18T08:20:43.492132Z","shell.execute_reply":"2022-04-18T08:20:43.497158Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['latin---reggaeton', 'pop---indie pop', 'rock---pop rock', 'hip hop---trap', 'rock---prog rock', 'funk / soul---disco', 'latin---salsa', 'funk / soul---rhythm & blues', 'funk / soul---soul', 'rock---punk', 'blues---country blues', 'pop---europop', 'latin---reggae', 'rock---alternative rock', 'rock---heavy metal', 'blues---electric blues', 'jazz---contemporary jazz', 'electronic---ambient', 'rock---hard rock', 'electronic---synth-pop', 'hip hop---pop rap', 'electronic---disco', 'electronic---house', 'classical---classical', 'classical---romantic', 'latin---flamenco', 'rock---nu metal', 'pop---ballad', 'rock---death metal', 'hip hop---instrumental', 'rock---goth rock', 'electronic---drum n bass', 'hip hop---conscious', 'electronic---downtempo', 'jazz---swing', 'rock---post rock', 'classical---baroque', 'classical---modern', 'latin---samba', 'electronic---new wave', 'rock---shoegaze', 'electronic---electro', 'jazz---soul-jazz', 'electronic---trip hop', 'classical---opera', 'rock---art rock', 'rock---post-punk', 'hip hop---trip hop', 'hip hop---gangsta', 'rock---new wave', 'latin---cubano', 'rock---viking metal']\n","output_type":"stream"}]},{"cell_type":"code","source":"operation = \"multiclass\"\n\nif operation  == \"multilabel\":\n    activation, loss, metrics = \"sigmoid\", \"binary_crossentropy\", \\\n        [\"categorical_accuracy\", keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", threshold=0.5)]\n    target_function = lambda t: subgenre_target(t, subgenre_list)\n\n    label_count = len(subgenre_list)\nelif operation  == \"mood\":\n    activation, loss, metrics = \"sigmoid\", \"binary_crossentropy\", [\"categorical_accuracy\", keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", threshold=0.5)]\n    target_function = lambda t: mood_target(t)\n    label_count = 7\nelif operation  == \"multiclass\":\n    activation, loss, metrics = \"softmax\", \"sparse_categorical_crossentropy\", [\"accuracy\"]\n    target_function = lambda t: genre_target(t, genres2labels)\n    label_count = len(genres)\nelse:\n    raise ValueError(\"Invalid Type\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:43.503951Z","iopub.execute_input":"2022-04-18T08:20:43.504134Z","iopub.status.idle":"2022-04-18T08:20:43.512020Z","shell.execute_reply.started":"2022-04-18T08:20:43.504111Z","shell.execute_reply":"2022-04-18T08:20:43.510573Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### Load the Data","metadata":{}},{"cell_type":"markdown","source":"#### Train the Model","metadata":{}},{"cell_type":"code","source":"mfccs = load_mfccs(subgenre_list, subgenres,  labels, max_per_genre = 700)\nrandom.shuffle(mfccs)\n\ntrain, test, val = train_test_val(mfccs)\n\nprint(f\"train {len(train)} + test {len(test)} + val {len(val)} = {len(train) + len(test) + len(val)}\" )\n\n# Initialize the dataset generators \ntrain_generator = TrackDataGen(train, target_function,  labels, oversample=True)\ntest_generator = TrackDataGen(test, target_function,  labels)\nvalidation_generator = TrackDataGen(val, target_function,  labels)\n\nshape = train_generator[0][0][0].shape\n\nprint(f\"shape: {shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:20:43.512891Z","iopub.execute_input":"2022-04-18T08:20:43.513091Z","iopub.status.idle":"2022-04-18T08:21:01.246452Z","shell.execute_reply.started":"2022-04-18T08:20:43.513067Z","shell.execute_reply":"2022-04-18T08:21:01.245577Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"train 4849 + test 62 + val 1228 = 6139\nshape: (32, 130, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"def ensemble_ova(models: List[Tuple[int, tf.keras.Model]], input_shape: Tuple[int]):\n    input_layer = keras.Input(shape=input_shape)\n\n    input_norm = input_layer\n    #input_layer = input_layer(keras.Input(shape=input_shape))\n\n    \n    \n    #models[0][1].summary()\n    \n    for genre, model in models:\n                \n        #model.name = genre\n\n        model.layers[0] = keras.Input(shape=input_shape) # Remove the input normalization layer\n        model.trainable = False\n        model._name = genre\n\n    \n    \n    model_outputs = [model(input_norm) for _, model in models]\n\n    \n    ova_output = keras.layers.Concatenate()(model_outputs)\n\n    ova = keras.Model(inputs=input_layer, outputs=ova_output)\n\n    ova.summary()\n    return ova","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:01.247992Z","iopub.execute_input":"2022-04-18T08:21:01.248471Z","iopub.status.idle":"2022-04-18T08:21:01.256391Z","shell.execute_reply.started":"2022-04-18T08:21:01.248430Z","shell.execute_reply":"2022-04-18T08:21:01.255565Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if operation  == \"moods\":\n    mood_ova_models = build_mood_ova(labels, train, val)\n    mood_ova = ensemble_ova(mood_ova_models, shape)\n    mood_ova.save(\"mood_ova.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:01.258047Z","iopub.execute_input":"2022-04-18T08:21:01.258354Z","iopub.status.idle":"2022-04-18T08:21:01.270502Z","shell.execute_reply.started":"2022-04-18T08:21:01.258315Z","shell.execute_reply":"2022-04-18T08:21:01.269794Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"if operation  == \"multiclass_\":\n    ova_models = build_ova(genres, labels, train, val)\n    model = ova = ensemble_ova(ova_models, shape)\n    ova.compile(optimizer = keras.optimizers.Adam(), loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\", tf.keras.metrics.BinaryAccuracy()])\n    #train_ova(ova)\n\n\n    ova.evaluate(validation_generator)\n    ova.save(\"ova.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:01.272084Z","iopub.execute_input":"2022-04-18T08:21:01.272753Z","iopub.status.idle":"2022-04-18T08:21:01.280276Z","shell.execute_reply.started":"2022-04-18T08:21:01.272712Z","shell.execute_reply":"2022-04-18T08:21:01.279557Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"if operation  == \"multiclass_\":\n    hits = 0\n    print(genres)\n    for i, v in enumerate(val):\n        real_res = res = ova.predict(normalize_data(v[\"mfccs\"]))\n        #print(res)\n        res = res.sum(axis=0)\n        lbl = res.argmax()\n\n        real_lbl = labels[\"tracks\"][v[\"track_id\"]][\"genre\"][\"S\"]\n\n\n        if (genres[lbl] == real_lbl):\n            hits += 1\n            #print(hits/max(i,1))\n        else:\n            continue\n            print(f\"{genres[lbl]} != {real_lbl} :: {res}\")\n            print(real_res)\n            print(res)\n\n\n    print(hits / len(val))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:01.281916Z","iopub.execute_input":"2022-04-18T08:21:01.282492Z","iopub.status.idle":"2022-04-18T08:21:01.290782Z","shell.execute_reply.started":"2022-04-18T08:21:01.282442Z","shell.execute_reply":"2022-04-18T08:21:01.290025Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:01.292397Z","iopub.execute_input":"2022-04-18T08:21:01.292928Z","iopub.status.idle":"2022-04-18T08:21:01.301025Z","shell.execute_reply.started":"2022-04-18T08:21:01.292889Z","shell.execute_reply":"2022-04-18T08:21:01.300195Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"(32, 130, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"if True:\n    conv_base = keras.applications.EfficientNetB0(\n                    include_top = False, \n                    weights = \"imagenet\",\n                    drop_connect_rate=0.8\n                    )\n\n    \n\n    model = keras.models.Sequential([\n                                    keras.layers.Conv2D(3,(3,3),padding='same', input_shape=shape ), \n                                    conv_base, \n                                    #keras.layers.BatchNormalization(),\n                                    #keras.layers.GlobalAveragePooling2D(),\n                                    keras.layers.BatchNormalization(),\n                                    #keras.layers.Dropout(0.5),\n                                    #keras.layers.Dense(512, activation=\"relu\"),\n                                    keras.layers.Flatten(),\n                                    keras.layers.Dropout(0.3),\n                                    keras.layers.Dense(512, activation=\"relu\"),\n\n                                    #keras.layers.Dense(256, activation=\"relu\"),\n                                    #keras.layers.Dropout(0.1),\n                                    keras.layers.Dense(label_count , activation = activation)])\n\nelse:\n    model = build_CNN(label_count , activation, shape)\nmodel.compile(optimizer = keras.optimizers.Adam(), loss = loss, metrics = metrics)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:01.302689Z","iopub.execute_input":"2022-04-18T08:21:01.303050Z","iopub.status.idle":"2022-04-18T08:21:04.287702Z","shell.execute_reply.started":"2022-04-18T08:21:01.303015Z","shell.execute_reply":"2022-04-18T08:21:04.286921Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"2022-04-18 08:21:01.330345: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-18 08:21:01.330784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:21:01.331675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:21:01.332385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:21:01.922388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:21:01.923269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:21:01.923950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 08:21:01.924567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:04.289020Z","iopub.execute_input":"2022-04-18T08:21:04.289268Z","iopub.status.idle":"2022-04-18T08:21:04.313971Z","shell.execute_reply.started":"2022-04-18T08:21:04.289235Z","shell.execute_reply":"2022-04-18T08:21:04.313186Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 130, 3)        30        \n_________________________________________________________________\nefficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1, 4, 1280)        5120      \n_________________________________________________________________\nflatten (Flatten)            (None, 5120)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 5120)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               2621952   \n_________________________________________________________________\ndense_1 (Dense)              (None, 9)                 4617      \n=================================================================\nTotal params: 6,681,290\nTrainable params: 6,636,707\nNon-trainable params: 44,583\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Build and train the net \n#model = build_network(\"multilabel\", labels=len(subgenre_list), shape=shape )\nhistory = model.fit(train_generator,\n                    validation_data = validation_generator, \n                    epochs=50,\n                    \n                    callbacks = [stop_callback, build_checkpoint_callback()],\n                    batch_size = BATCH_SIZE\n                )\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:21:04.315122Z","iopub.execute_input":"2022-04-18T08:21:04.315397Z","iopub.status.idle":"2022-04-18T08:38:35.973528Z","shell.execute_reply.started":"2022-04-18T08:21:04.315358Z","shell.execute_reply":"2022-04-18T08:38:35.972310Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2022-04-18 08:21:04.365951: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-04-18 08:21:12.704895: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1800/1800 [==============================] - 101s 51ms/step - loss: 1.7849 - accuracy: 0.3773 - val_loss: 1.5492 - val_accuracy: 0.4797\n\nEpoch 00001: val_accuracy improved from -inf to 0.47971, saving model to ./checkpoint/saved_model.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50\n1800/1800 [==============================] - 91s 50ms/step - loss: 1.5196 - accuracy: 0.4642 - val_loss: 1.5043 - val_accuracy: 0.4721\n\nEpoch 00002: val_accuracy did not improve from 0.47971\nEpoch 3/50\n1800/1800 [==============================] - 91s 51ms/step - loss: 1.4237 - accuracy: 0.5028 - val_loss: 1.6444 - val_accuracy: 0.4433\n\nEpoch 00003: val_accuracy did not improve from 0.47971\nEpoch 4/50\n1800/1800 [==============================] - 90s 50ms/step - loss: 1.3410 - accuracy: 0.5341 - val_loss: 1.3862 - val_accuracy: 0.5350\n\nEpoch 00004: val_accuracy improved from 0.47971 to 0.53501, saving model to ./checkpoint/saved_model.h5\nEpoch 5/50\n1800/1800 [==============================] - 90s 50ms/step - loss: 1.2624 - accuracy: 0.5641 - val_loss: 1.3326 - val_accuracy: 0.5491\n\nEpoch 00005: val_accuracy improved from 0.53501 to 0.54910, saving model to ./checkpoint/saved_model.h5\nEpoch 6/50\n1800/1800 [==============================] - 91s 51ms/step - loss: 1.1827 - accuracy: 0.5926 - val_loss: 1.4433 - val_accuracy: 0.5251\n\nEpoch 00006: val_accuracy did not improve from 0.54910\nEpoch 7/50\n1800/1800 [==============================] - 90s 50ms/step - loss: 1.0996 - accuracy: 0.6233 - val_loss: 1.4239 - val_accuracy: 0.5378\n\nEpoch 00007: val_accuracy did not improve from 0.54910\nEpoch 8/50\n1800/1800 [==============================] - 91s 50ms/step - loss: 1.0185 - accuracy: 0.6528 - val_loss: 1.4675 - val_accuracy: 0.5257\n\nEpoch 00008: val_accuracy did not improve from 0.54910\nEpoch 9/50\n1800/1800 [==============================] - 90s 50ms/step - loss: 0.9383 - accuracy: 0.6796 - val_loss: 1.6234 - val_accuracy: 0.5175\n\nEpoch 00009: val_accuracy did not improve from 0.54910\nEpoch 10/50\n1800/1800 [==============================] - 91s 51ms/step - loss: 0.8535 - accuracy: 0.7111 - val_loss: 1.5929 - val_accuracy: 0.5284\n\nEpoch 00010: val_accuracy did not improve from 0.54910\nEpoch 11/50\n1800/1800 [==============================] - 90s 50ms/step - loss: 0.7812 - accuracy: 0.7369 - val_loss: 1.6407 - val_accuracy: 0.5137\n\nEpoch 00011: val_accuracy did not improve from 0.54910\nEpoch 12/50\n 866/1800 [=============>................] - ETA: 44s - loss: 0.6756 - accuracy: 0.7727","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2419/1641121518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstop_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from sklearn import svm\n\n\ndef cnn_svm(model, train_generator, val_generator):\n    \n    model2 = keras.Model(inputs=model.input, outputs=model.layers[-3].output)\n    model2.summary()\n    x_train, y_train = train_generator.to_numpy()\n    x_test, y_test = train_generator.to_numpy()\n    \n    cnn_infer_time = time()\n    svm_input_data = model.predict(x_train)\n    cnn_infer_time = time() - cnn_infer_time\n    svmc = svm.SVC()\n    svmc.fit(svm_input_data, y_train)\n    \n    \n    svm_input_test = model.predict(x_test)\n    \n    svm_infer_time = time()\n    res = svmc.predict(svm_input_test)\n    svm_infer_time = time() - svm_infer_time\n    hits = 0\n\n    \n    print(f\"CNN {cnn_infer_time}\")\n    print(f\"SVM {svm_infer_time}\")\n\n    for pred, real in zip(res, y_test):\n        if pred == real:\n            hits += 1\n\n    print(hits / len(x_train))\n            ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:46.968176Z","iopub.execute_input":"2022-04-18T08:38:46.968394Z","iopub.status.idle":"2022-04-18T08:38:47.004081Z","shell.execute_reply.started":"2022-04-18T08:38:46.968367Z","shell.execute_reply":"2022-04-18T08:38:47.003431Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"cnn_svm(model, train_generator, validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:39:04.041461Z","iopub.execute_input":"2022-04-18T08:39:04.042061Z","iopub.status.idle":"2022-04-18T08:47:04.636454Z","shell.execute_reply.started":"2022-04-18T08:39:04.042020Z","shell.execute_reply":"2022-04-18T08:47:04.635664Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_input (InputLayer)    [(None, 32, 130, 1)]      0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 32, 130, 3)        30        \n_________________________________________________________________\nefficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1, 4, 1280)        5120      \n_________________________________________________________________\nflatten (Flatten)            (None, 5120)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 5120)              0         \n=================================================================\nTotal params: 4,054,721\nTrainable params: 4,010,138\nNon-trainable params: 44,583\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2022-04-18 08:39:04.068731: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 778752000 exceeds 10% of free system memory.\n2022-04-18 08:39:04.896174: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 778752000 exceeds 10% of free system memory.\n2022-04-18 08:43:27.313458: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 778752000 exceeds 10% of free system memory.\n2022-04-18 08:43:28.084383: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 778752000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"CNN 23.430569887161255\nSVM 195.49100756645203\n0.16085470085470085\n","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.models.load_model(\"./checkpoint/saved_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:43.885090Z","iopub.execute_input":"2022-04-18T08:38:43.885813Z","iopub.status.idle":"2022-04-18T08:38:46.965840Z","shell.execute_reply.started":"2022-04-18T08:38:43.885756Z","shell.execute_reply":"2022-04-18T08:38:46.964977Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:35.980576Z","iopub.status.idle":"2022-04-18T08:38:35.981357Z","shell.execute_reply.started":"2022-04-18T08:38:35.981104Z","shell.execute_reply":"2022-04-18T08:38:35.981130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import normalize\nif operation == \"multiclass\":\n    import seaborn as sn\n    def conf_matrix(dataset: List[Mfcc]):\n        real_labels = []\n        pred_labels = []\n        hit = 0\n\n        for track in dataset:\n            \n            res = model.predict(normalize_data(np.expand_dims(track[\"mfccs\"], axis=3)))\n            \n            res_sum = res.sum(axis=0)\n            pred = np.argmax(res_sum)\n            real = get_track_labels(track[\"track_id\"])\n            \n            pred_labels.append(pred)\n            real_labels.append(real)\n            if pred == real:\n                hit +=1 \n        print(f\"Accuracy: {hit / len(real_labels)}\")\n        conf_m = tf.math.confusion_matrix(labels=real_labels, predictions=pred_labels )\n        \n        norm_conf_m = normalize(conf_m, axis=1, norm='l1') \n        \n        print(conf_m)\n        \n        genres = [labels2genres.get(i, \"\")[:3] for i in range(len(labels2genres))]\n        df_cm = pd.DataFrame(conf_m, \n                             index=genres,columns=genres, \n                             dtype=np.int32)\n\n        plt.figure(figsize = (10,7))\n        sn.heatmap(df_cm, annot=True)\n        \n        df_cm = pd.DataFrame(norm_conf_m, \n                             index=genres,columns=genres, \n                             dtype=np.float32)\n\n        plt.figure(figsize = (10,7))\n        sn.heatmap(df_cm, annot=True)\n    conf_matrix(val)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:35.982497Z","iopub.status.idle":"2022-04-18T08:38:35.983308Z","shell.execute_reply.started":"2022-04-18T08:38:35.983060Z","shell.execute_reply":"2022-04-18T08:38:35.983087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if operation == \"mood\":\n    for track in val:\n        print(track[\"track_id\"])\n        track_label = get_track_labels(track[\"track_id\"])\n        pred = model.predict(track[\"mfccs\"])\n        res = pred.mean(axis=0)\n        res = [1 if pred > 0.5 else 0 for pred in res]\n        print(f\"Pred: {res}\")\n        print(f\"Res : {track_label}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:35.984420Z","iopub.status.idle":"2022-04-18T08:38:35.985218Z","shell.execute_reply.started":"2022-04-18T08:38:35.984968Z","shell.execute_reply":"2022-04-18T08:38:35.984993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analyze the Results ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"track = test[8]\nres = model.predict(track[\"mfccs\"])\nprint(res)\nprint(res.sum(axis=0))\nprint([1 if x > 0.5 * track[\"splits\"] else 0 for x in res.sum(axis=0)])\nprint(target_function(labels[\"tracks\"][track[\"track_id\"]]))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:35.986342Z","iopub.status.idle":"2022-04-18T08:38:35.987099Z","shell.execute_reply.started":"2022-04-18T08:38:35.986857Z","shell.execute_reply":"2022-04-18T08:38:35.986883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\ndef plot_conf_matrix(model: keras.Model, data: List[Mfcc]):\n\n    predicted = []\n    real = []\n\n    for track in data:\n        res = model.predict(track[\"mfccs\"])\n        res_sum = res.sum(axis=0)\n        res = [1 if i > 0.5 * track[\"splits\"] else 0 for i in res_sum]\n        predicted.append(res)\n        real.append(get_track_labels(track[\"track_id\"]))\n    \n\n    \n    print(np.mean(tf.keras.metrics.binary_accuracy(real, predicted, )))\n    \n    for r, p in zip(real, predicted):\n        r_p = np.sum(r, p, axis = 0)\n    \n    assert len(predicted) == len(real)\n    \n    conf_m = multilabel_confusion_matrix(predicted, real)\n    print(conf_m)\n    print(np.array(conf_m).sum(axis=0))\n    return \n    df_cm = pd.DataFrame(conf_m, index=genres, # type: ignore\n                  columns=genres, dtype=np.int8)\n    #plt.figure(figsize = (10,7))\n    #seaborn.heatmap(df_cm, annot=True)   \n\nplot_conf_matrix(model,val)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T08:38:35.988244Z","iopub.status.idle":"2022-04-18T08:38:35.989088Z","shell.execute_reply.started":"2022-04-18T08:38:35.988848Z","shell.execute_reply":"2022-04-18T08:38:35.988874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}